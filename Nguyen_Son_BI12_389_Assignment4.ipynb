{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGcNXgEH9S3s"
      },
      "source": [
        "# Named Entity Recognition with MIT Restaurant Dataset\n",
        "\n",
        "Your name: Nguyen Son\n",
        "\n",
        "Student ID: BI12-389\n",
        "\n",
        "**Not overdued yet**\n",
        "\n",
        "## Task Description\n",
        "\n",
        "In this assignment, you will train a NER Model using Conditional Random Fields (CRF) on and report the accuracy of your model on the test dataset.\n",
        "\n",
        "You will use the [MIT Restaurant Dataset](https://groups.csail.mit.edu/sls/downloads/restaurant/) dataset to do the task.\n",
        "\n",
        "## How to submit\n",
        "\n",
        "- Attach notebook file (.ipynb) and submit your work to Google Class Room\n",
        "- Name your file as YourName_StudentID_Assignment4.ibynb. E.g., Nguyen_Van_A_ST099834_Assignment4.ipynb\n",
        "- Write your name and student ID into this notebook\n",
        "- Copying others' assignments is strictly prohibited.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-wE5Ygy_851"
      },
      "source": [
        "## Install python-crfsuite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhjb-9J2AAMu",
        "outputId": "e17ceb87-ac23-428a-ea53-000bb19c4520"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q python-crfsuite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26ieJ1aEAQs-"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGewX5VmASAU"
      },
      "outputs": [],
      "source": [
        "from itertools import chain\n",
        "import pycrfsuite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ie-POGzEv8xA"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "We will use [MIT Restaurant Dataset](https://groups.csail.mit.edu/sls/downloads/restaurant/) dataset.\n",
        "\n",
        "The data set is already in CoNLL format. We will use the [train](https://groups.csail.mit.edu/sls/downloads/restaurant/restauranttrain.bio) data to create the NER model and evaluate the model on the [test](https://groups.csail.mit.edu/sls/downloads/restaurant/restauranttest.bio) data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2U0ME8SbxIS2"
      },
      "source": [
        "### Download data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PcFJBAy7xa-x"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!rm -f restauranttrain.bio\n",
        "!rm -f restauranttest.bio\n",
        "\n",
        "!wget https://groups.csail.mit.edu/sls/downloads/restaurant/restauranttest.bio\n",
        "!wget https://groups.csail.mit.edu/sls/downloads/restaurant/restauranttrain.bio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLyiSFarytjC"
      },
      "source": [
        "## Loading data (30 points)\n",
        "\n",
        "In this part, you will load a data file into a list of sentences. Each sentence is a list of (word, tag) tuples.\n",
        "\n",
        "**Note: Blank lines are used to seperate sentences.**\n",
        "\n",
        "For instance, the sentence below will be loaded into a list\n",
        "\n",
        "```\n",
        "O\ta\n",
        "B-Rating\tfour\n",
        "I-Rating\tstar\n",
        "O\trestaurant\n",
        "B-Location\twith\n",
        "I-Location\ta\n",
        "B-Amenity\tbar\n",
        "```\n",
        "\n",
        "You will complete the function below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6UmjUBP06c4"
      },
      "outputs": [],
      "source": [
        "## Add necessary import here\n",
        "\n",
        "def load_data(file_path):\n",
        "    \"\"\"Load data into a list of list of (word, tag) tuples\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to data\n",
        "\n",
        "    Returns:\n",
        "        sentences: list of (word, tag) tuples\n",
        "    \"\"\"\n",
        "    sentences = []\n",
        "\n",
        "    current_sentence = []\n",
        "\n",
        "    with open(file_path, 'r') as file:\n",
        "        for line in file:\n",
        "            if line == '\\n':\n",
        "                if current_sentence:\n",
        "                    sentences.append(current_sentence)\n",
        "                    current_sentence = []\n",
        "            else:\n",
        "                parts = line.strip().split('\\t')\n",
        "                if len(parts) == 2:\n",
        "                    current_sentence.append((parts[0], parts[1]))\n",
        "\n",
        "    if current_sentence:\n",
        "        sentences.append(current_sentence)\n",
        "\n",
        "    return sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zy6fIDnF19nC"
      },
      "outputs": [],
      "source": [
        "train_sents = load_data('restauranttrain.bio')\n",
        "test_sents = load_data('restauranttest.bio')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOzFyaKo2Wgl"
      },
      "source": [
        "Let's check the number of sentences in train and test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVdNqwKH2mi8",
        "outputId": "235c0a75-61e6-4eaf-eda7-d3ffaefda83c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7660"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_sents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVVcSv6r2oq6",
        "outputId": "25b4e4ce-d924-47e0-9005-d16807ac28dc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1521"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(test_sents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Msy21RWM232U",
        "outputId": "3e969525-37f5-4d5c-a784-f414c392a5ee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[('B-Rating', '2'),\n",
              "  ('I-Rating', 'start'),\n",
              "  ('O', 'restaurants'),\n",
              "  ('O', 'with'),\n",
              "  ('B-Amenity', 'inside'),\n",
              "  ('I-Amenity', 'dining')],\n",
              " [('O', '34')],\n",
              " [('B-Rating', '5'),\n",
              "  ('I-Rating', 'star'),\n",
              "  ('O', 'resturants'),\n",
              "  ('B-Location', 'in'),\n",
              "  ('I-Location', 'my'),\n",
              "  ('I-Location', 'town')]]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_sents[:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVv2iYez3CBW"
      },
      "source": [
        "## Features (50 points)\n",
        "\n",
        "We can extract as many features as you want. You will implement following basic features.\n",
        "\n",
        "※ Of course, you can add more features.\n",
        "\n",
        "*Word identity (lowercase)*\n",
        "\n",
        "- Previous word identity\n",
        "- Current word identity\n",
        "- Next word\n",
        "- Previous word and current word combination. Concat the previous word the current word by '||'\n",
        "- Current word and next word combination. Concat two words by '||'\n",
        "\n",
        "*Word shapes*\n",
        "\n",
        "- Word prefix and suffix (4 characters)\n",
        "- The first character of the current word is the capital letter\n",
        "\n",
        "**All you need to do is to complete the function `word2feature`.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfBAsejb5iir"
      },
      "outputs": [],
      "source": [
        "def word2features(sentence, i):\n",
        "    \"\"\"\n",
        "    Extract features for the word at position i in the sentence.\n",
        "    \"\"\"\n",
        "    word = sentence[i][0]\n",
        "    features = {\n",
        "        'bias': 1.0,\n",
        "        'word.lower()': word.lower(),\n",
        "        'word[-3:]': word[-3:],\n",
        "        'word[-2:]': word[-2:],\n",
        "        'word.isupper()': word.isupper(),\n",
        "        'word.istitle()': word.istitle(),\n",
        "        'word.isdigit()': word.isdigit(),\n",
        "    }\n",
        "\n",
        "    if i > 0:\n",
        "        prev_word = sentence[i-1][0]\n",
        "        features.update({\n",
        "            'prev_word.lower()': prev_word.lower(),\n",
        "            'prev_word.istitle()': prev_word.istitle(),\n",
        "            'prev_word.isupper()': prev_word.isupper(),\n",
        "            'word+prev_word': word.lower() + '||' + prev_word.lower(),\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True  # Beginning of Sentence\n",
        "\n",
        "    if i < len(sentence)-1:\n",
        "        next_word = sentence[i+1][0]\n",
        "        features.update({\n",
        "            'next_word.lower()': next_word.lower(),\n",
        "            'next_word.istitle()': next_word.istitle(),\n",
        "            'next_word.isupper()': next_word.isupper(),\n",
        "            'word+next_word': word.lower() + '||' + next_word.lower(),\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True  # End of Sentence\n",
        "\n",
        "    return features\n",
        "\n",
        "\n",
        "def sent2features(sentence):\n",
        "    \"\"\"\n",
        "    sentence is a list of words [w1, w2,...,w_n]\n",
        "    \"\"\"\n",
        "    return [word2features(sentence, i) for i in range(len(sentence))]\n",
        "\n",
        "\n",
        "def sent2labels(sentence):\n",
        "    \"\"\"\n",
        "    sentence is a list of tuples (word, postag)\n",
        "    \"\"\"\n",
        "    return [tag for token, tag in sentence]\n",
        "\n",
        "def untag(sentence):\n",
        "    \"\"\"\n",
        "    sentence is a list of tuples (word, postag)\n",
        "    \"\"\"\n",
        "    return [token for token, _ in sentence]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7fSWZJQ83Vx"
      },
      "source": [
        "Let's try to extract features for the first sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNrn8zBrS-Sa",
        "outputId": "416b7c56-5964-4eea-82a8-3a2dde52c3c8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('B-Rating', '2'),\n",
              " ('I-Rating', 'start'),\n",
              " ('O', 'restaurants'),\n",
              " ('O', 'with'),\n",
              " ('B-Amenity', 'inside'),\n",
              " ('I-Amenity', 'dining')]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_sents[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFTpTYO68tfD",
        "outputId": "76f2d5f7-c6c8-4f5d-ce69-54032ec1b2e9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'bias': 1.0,\n",
              " 'word.lower()': 'b',\n",
              " 'word[-3:]': 'B',\n",
              " 'word[-2:]': 'B',\n",
              " 'word.isupper()': True,\n",
              " 'word.istitle()': True,\n",
              " 'word.isdigit()': False,\n",
              " 'BOS': True,\n",
              " 'next_word.lower()': 'i',\n",
              " 'next_word.istitle()': True,\n",
              " 'next_word.isupper()': True,\n",
              " 'word+next_word': 'b||i'}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sent2features(untag(train_sents[0]))[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Xl5Tyd4-zZv"
      },
      "source": [
        "### Create train/test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKUVYzMQ-3ef"
      },
      "outputs": [],
      "source": [
        "X_train = [sent2features(untag(s)) for s in train_sents]\n",
        "y_train = [sent2labels(s) for s in train_sents]\n",
        "\n",
        "X_test = [sent2features(untag(s)) for s in test_sents]\n",
        "y_test = [sent2labels(s) for s in test_sents]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "La08Oyam_ZjN"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-C-fq8x_brV",
        "outputId": "db7886f3-d603-43b0-9255-6a8f1f14b811"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 704 ms, sys: 21.1 ms, total: 725 ms\n",
            "Wall time: 756 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "trainer = pycrfsuite.Trainer(verbose=False)\n",
        "\n",
        "for xseq, yseq in zip(X_train, y_train):\n",
        "    trainer.append(xseq, yseq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0XJtpOtO2Pl",
        "outputId": "8a5dded6-7c9d-4c6e-dd88-6710cf341551"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Appending training data...\n",
            "Training data appended. Setting parameters...\n",
            "Parameters set. Starting training...\n",
            "Feature generation\n",
            "type: CRF1d\n",
            "feature.minfreq: 0.000000\n",
            "feature.possible_states: 0\n",
            "feature.possible_transitions: 1\n",
            "0....1....2....3....4....5....6....7....8....9....10"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import pycrfsuite\n",
        "\n",
        "# Start timing\n",
        "start_time = time.time()\n",
        "\n",
        "# Initialize trainer with verbose output enabled\n",
        "trainer = pycrfsuite.Trainer(verbose=True)\n",
        "\n",
        "print(\"Appending training data...\")\n",
        "\n",
        "for xseq, yseq in zip(X_train, y_train):\n",
        "    trainer.append(xseq, yseq)\n",
        "\n",
        "print(\"Training data appended. Setting parameters...\")\n",
        "\n",
        "max_iterations = 20  # Set your desired number of max iterations\n",
        "\n",
        "trainer.set_params({\n",
        "    'c1': 1.0,  # coefficient for L1 penalty\n",
        "    'c2': 1e-3,  # coefficient for L2 penalty\n",
        "    'max_iterations': max_iterations,\n",
        "    'feature.possible_transitions': True\n",
        "})\n",
        "\n",
        "print(\"Parameters set. Starting training...\")\n",
        "\n",
        "trainer.train('mitrestaurant.crfsuite')\n",
        "\n",
        "print(\"Training completed.\")\n",
        "\n",
        "# Training finished, stop timing\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate and print the elapsed time\n",
        "elapsed_time = end_time - start_time\n",
        "print(f\"Total training time: {elapsed_time:.2f} seconds\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQQLY7m-PPmO"
      },
      "source": [
        "## Evaluation (20 points)\n",
        "\n",
        "We will use [seqeval](https://github.com/chakki-works/seqeval) package for evaluation NER result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GtpO8Mb4dFMg"
      },
      "outputs": [],
      "source": [
        "!pip install -q seqeval[cpu]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UCqdlNvPWZM"
      },
      "source": [
        "### Make Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UVenrYzcPYoM"
      },
      "outputs": [],
      "source": [
        "tagger = pycrfsuite.Tagger()\n",
        "tagger.open('mitrestaurant.crfsuite')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rAfV8QhcPb9e"
      },
      "outputs": [],
      "source": [
        "example_sent = test_sents[0]\n",
        "example_sent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hGrDn-4P55R"
      },
      "outputs": [],
      "source": [
        "print(\"Predicted:\", ' '.join(tagger.tag(sent2features(untag(example_sent)))))\n",
        "print(\"Correct:  \", ' '.join(sent2labels(example_sent)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ee18ZKIQqgU"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "y_pred = [tagger.tag(xseq) for xseq in X_test]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ns2UeFU5U96O"
      },
      "outputs": [],
      "source": [
        "from seqeval.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRMhFCCEBhds"
      },
      "source": [
        "# References\n",
        "\n",
        "1. Datasets for Entity Recognition: https://github.com/juand-r/entity-recognition-datasets\n",
        "2. [sklearn-crfsuite tutorial](https://sklearn-crfsuite.readthedocs.io/en/latest/tutorial.html#let-s-use-conll-2002-data-to-build-a-ner-system).\n",
        "3. [Quick Recipe: Build a POS tagger using a Conditional Random Field](https://nlpforhackers.io/crf-pos-tagger/)\n",
        "4. [NLP Guide: Identifying Part of Speech Tags using Conditional Random Fields](https://medium.com/analytics-vidhya/pos-tagging-using-conditional-random-fields-92077e5eaa31)\n",
        "5. [CRFsuite - Tutorial on Chunking Task](http://www.chokkan.org/software/crfsuite/tutorial.html)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}