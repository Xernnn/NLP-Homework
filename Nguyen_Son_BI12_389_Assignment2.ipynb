{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGcNXgEH9S3s"
      },
      "source": [
        "# Named Entity Recognition with MIT Restaurant Dataset\n",
        "\n",
        "Your name: Nguyen Son\n",
        "\n",
        "Student ID: BI12-389\n",
        "\n",
        "**Not overdued yet**\n",
        "\n",
        "## Task Description\n",
        "\n",
        "In this assignment, you will train a NER Model using Conditional Random Fields (CRF) on and report the accuracy of your model on the test dataset.\n",
        "\n",
        "You will use the [MIT Restaurant Dataset](https://groups.csail.mit.edu/sls/downloads/restaurant/) dataset to do the task.\n",
        "\n",
        "## How to submit\n",
        "\n",
        "- Attach notebook file (.ipynb) and submit your work to Google Class Room\n",
        "- Name your file as YourName_StudentID_Assignment4.ibynb. E.g., Nguyen_Van_A_ST099834_Assignment4.ipynb\n",
        "- Write your name and student ID into this notebook\n",
        "- Copying others' assignments is strictly prohibited.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-wE5Ygy_851"
      },
      "source": [
        "## Install python-crfsuite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qhjb-9J2AAMu"
      },
      "outputs": [],
      "source": [
        "!pip install -q python-crfsuite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26ieJ1aEAQs-"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yGewX5VmASAU"
      },
      "outputs": [],
      "source": [
        "from itertools import chain\n",
        "import pycrfsuite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ie-POGzEv8xA"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "We will use [MIT Restaurant Dataset](https://groups.csail.mit.edu/sls/downloads/restaurant/) dataset.\n",
        "\n",
        "The data set is already in CoNLL format. We will use the [train](https://groups.csail.mit.edu/sls/downloads/restaurant/restauranttrain.bio) data to create the NER model and evaluate the model on the [test](https://groups.csail.mit.edu/sls/downloads/restaurant/restauranttest.bio) data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2U0ME8SbxIS2"
      },
      "source": [
        "### Download data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PcFJBAy7xa-x"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!rm -f restauranttrain.bio\n",
        "!rm -f restauranttest.bio\n",
        "\n",
        "!wget https://groups.csail.mit.edu/sls/downloads/restaurant/restauranttest.bio\n",
        "!wget https://groups.csail.mit.edu/sls/downloads/restaurant/restauranttrain.bio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLyiSFarytjC"
      },
      "source": [
        "## Loading data (30 points)\n",
        "\n",
        "In this part, you will load a data file into a list of sentences. Each sentence is a list of (word, tag) tuples.\n",
        "\n",
        "**Note: Blank lines are used to seperate sentences.**\n",
        "\n",
        "For instance, the sentence below will be loaded into a list\n",
        "\n",
        "```\n",
        "O\ta\n",
        "B-Rating\tfour\n",
        "I-Rating\tstar\n",
        "O\trestaurant\n",
        "B-Location\twith\n",
        "I-Location\ta\n",
        "B-Amenity\tbar\n",
        "```\n",
        "\n",
        "You will complete the function below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "M6UmjUBP06c4"
      },
      "outputs": [],
      "source": [
        "## Add necessary import here\n",
        "\n",
        "def load_data(file_path):\n",
        "    \"\"\"Load data into a list of list of (word, tag) tuples\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to data\n",
        "\n",
        "    Returns:\n",
        "        sentences: list of (word, tag) tuples\n",
        "    \"\"\"\n",
        "    sentences = []\n",
        "\n",
        "    current_sentence = []\n",
        "\n",
        "    with open(file_path, 'r') as file:\n",
        "        for line in file:\n",
        "            if line == '\\n':\n",
        "                if current_sentence:\n",
        "                    sentences.append(current_sentence)\n",
        "                    current_sentence = []\n",
        "            else:\n",
        "                parts = line.strip().split('\\t')\n",
        "                if len(parts) == 2:\n",
        "                    current_sentence.append((parts[1], parts[0]))\n",
        "\n",
        "    if current_sentence:\n",
        "        sentences.append(current_sentence)\n",
        "\n",
        "    return sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zy6fIDnF19nC"
      },
      "outputs": [],
      "source": [
        "train_sents = load_data('restauranttrain.bio')\n",
        "test_sents = load_data('restauranttest.bio')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOzFyaKo2Wgl"
      },
      "source": [
        "Let's check the number of sentences in train and test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jVdNqwKH2mi8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd371adb-4f21-4758-ef55-c1650afd714a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7660"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "len(train_sents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "sVVcSv6r2oq6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d51b6274-b853-4f00-91af-25207307071d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1521"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "len(test_sents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Msy21RWM232U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13bb8bcb-efd5-4449-b983-afac57ed6dc4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('2', 'B-Rating'),\n",
              " ('start', 'I-Rating'),\n",
              " ('restaurants', 'O'),\n",
              " ('with', 'O'),\n",
              " ('inside', 'B-Amenity'),\n",
              " ('dining', 'I-Amenity')]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "train_sents[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVv2iYez3CBW"
      },
      "source": [
        "## Features (50 points)\n",
        "\n",
        "We can extract as many features as you want. You will implement following basic features.\n",
        "\n",
        "â€» Of course, you can add more features.\n",
        "\n",
        "*Word identity (lowercase)*\n",
        "\n",
        "- Previous word identity\n",
        "- Current word identity\n",
        "- Next word\n",
        "- Previous word and current word combination. Concat the previous word the current word by '||'\n",
        "- Current word and next word combination. Concat two words by '||'\n",
        "\n",
        "*Word shapes*\n",
        "\n",
        "- Word prefix and suffix (4 characters)\n",
        "- The first character of the current word is the capital letter\n",
        "\n",
        "**All you need to do is to complete the function `word2feature`.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "yfBAsejb5iir"
      },
      "outputs": [],
      "source": [
        "def word2features(sentence, i):\n",
        "    \"\"\"\n",
        "    Extract features for the word at position i in the sentence.\n",
        "    \"\"\"\n",
        "    word = sentence[i][0]\n",
        "    features = {\n",
        "        'bias': 1.0,\n",
        "        'word.lower()': word.lower(),\n",
        "        'word[-3:]': word[-3:],\n",
        "        'word[-2:]': word[-2:],\n",
        "        'word.isupper()': word.isupper(),\n",
        "        'word.istitle()': word.istitle(),\n",
        "        'word.isdigit()': word.isdigit(),\n",
        "    }\n",
        "\n",
        "    if i > 0:\n",
        "        prev_word = sentence[i-1][0]\n",
        "        features.update({\n",
        "            'prev_word.lower()': prev_word.lower(),\n",
        "            'prev_word.istitle()': prev_word.istitle(),\n",
        "            'prev_word.isupper()': prev_word.isupper(),\n",
        "            'word+prev_word': word.lower() + '||' + prev_word.lower(),\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True  # Beginning of Sentence\n",
        "\n",
        "    if i < len(sentence)-1:\n",
        "        next_word = sentence[i+1][0]\n",
        "        features.update({\n",
        "            'next_word.lower()': next_word.lower(),\n",
        "            'next_word.istitle()': next_word.istitle(),\n",
        "            'next_word.isupper()': next_word.isupper(),\n",
        "            'word+next_word': word.lower() + '||' + next_word.lower(),\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True  # End of Sentence\n",
        "\n",
        "    return features\n",
        "\n",
        "\n",
        "def sent2features(sentence):\n",
        "    \"\"\"\n",
        "    sentence is a list of words [w1, w2,...,w_n]\n",
        "    \"\"\"\n",
        "    return [word2features(sentence, i) for i in range(len(sentence))]\n",
        "\n",
        "\n",
        "def sent2labels(sentence):\n",
        "    \"\"\"\n",
        "    sentence is a list of tuples (word, postag)\n",
        "    \"\"\"\n",
        "    return [tag for token, tag in sentence]\n",
        "\n",
        "def untag(sentence):\n",
        "    \"\"\"\n",
        "    sentence is a list of tuples (word, postag)\n",
        "    \"\"\"\n",
        "    return [token for token, _ in sentence]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7fSWZJQ83Vx"
      },
      "source": [
        "Let's try to extract features for the first sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "iNrn8zBrS-Sa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19f88a43-4ee5-4c99-d631-54c4f994c53b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('2', 'B-Rating'),\n",
              " ('start', 'I-Rating'),\n",
              " ('restaurants', 'O'),\n",
              " ('with', 'O'),\n",
              " ('inside', 'B-Amenity'),\n",
              " ('dining', 'I-Amenity')]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "train_sents[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "KFTpTYO68tfD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6cc6ad9-cda2-4129-8387-3bf19f55f133"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bias': 1.0,\n",
              " 'word.lower()': '2',\n",
              " 'word[-3:]': '2',\n",
              " 'word[-2:]': '2',\n",
              " 'word.isupper()': False,\n",
              " 'word.istitle()': False,\n",
              " 'word.isdigit()': True,\n",
              " 'BOS': True,\n",
              " 'next_word.lower()': 's',\n",
              " 'next_word.istitle()': False,\n",
              " 'next_word.isupper()': False,\n",
              " 'word+next_word': '2||s'}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "sent2features(untag(train_sents[0]))[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Xl5Tyd4-zZv"
      },
      "source": [
        "### Create train/test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "nKUVYzMQ-3ef"
      },
      "outputs": [],
      "source": [
        "X_train = [sent2features(untag(s)) for s in train_sents]\n",
        "y_train = [sent2labels(s) for s in train_sents]\n",
        "\n",
        "X_test = [sent2features(untag(s)) for s in test_sents]\n",
        "y_test = [sent2labels(s) for s in test_sents]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "La08Oyam_ZjN"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "5-C-fq8x_brV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5072fce-3361-40b3-f6d9-ac2bb443f519"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 794 ms, sys: 17.1 ms, total: 812 ms\n",
            "Wall time: 1.03 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "trainer = pycrfsuite.Trainer(verbose=False)\n",
        "\n",
        "for xseq, yseq in zip(X_train, y_train):\n",
        "    trainer.append(xseq, yseq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "C0XJtpOtO2Pl"
      },
      "outputs": [],
      "source": [
        "#@title Set model parameters\n",
        "\n",
        "max_iterations = \"100\" #@param[50, 20, 100]\n",
        "\n",
        "trainer.set_params({\n",
        "    'c1': 1.0,   # coefficient for L1 penalty\n",
        "    'c2': 1e-4,  # coefficient for L2 penalty\n",
        "    'max_iterations': max_iterations,\n",
        "\n",
        "    # include transitions that are possible, but not observed\n",
        "    'feature.possible_transitions': True\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "trainer.train('mitrestaurant.crfsuite')"
      ],
      "metadata": {
        "id": "ZjkL2UIhKxDC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8569059d-adce-4f1d-ee0e-e90a0703d9d4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 16.7 s, sys: 86.4 ms, total: 16.7 s\n",
            "Wall time: 17.9 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQQLY7m-PPmO"
      },
      "source": [
        "## Evaluation (20 points)\n",
        "\n",
        "We will use [seqeval](https://github.com/chakki-works/seqeval) package for evaluation NER result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "GtpO8Mb4dFMg"
      },
      "outputs": [],
      "source": [
        "!pip install -q seqeval[cpu]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UCqdlNvPWZM"
      },
      "source": [
        "### Make Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "UVenrYzcPYoM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75ef419a-b363-4c46-b33e-a981495fd678"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<contextlib.closing at 0x7c42dc10ba90>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "tagger = pycrfsuite.Tagger()\n",
        "tagger.open('mitrestaurant.crfsuite')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "rAfV8QhcPb9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22a71db1-ae79-4617-807a-a743827f5efa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('a', 'O'),\n",
              " ('four', 'B-Rating'),\n",
              " ('star', 'I-Rating'),\n",
              " ('restaurant', 'O'),\n",
              " ('with', 'B-Location'),\n",
              " ('a', 'I-Location'),\n",
              " ('bar', 'B-Amenity')]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "example_sent = test_sents[0]\n",
        "example_sent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "8hGrDn-4P55R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33c60f87-05a7-4202-f389-843b41a7f91f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: O B-Rating I-Rating O O O B-Amenity\n",
            "Correct:   O B-Rating I-Rating O B-Location I-Location B-Amenity\n"
          ]
        }
      ],
      "source": [
        "print(\"Predicted:\", ' '.join(tagger.tag(sent2features(untag(example_sent)))))\n",
        "print(\"Correct:  \", ' '.join(sent2labels(example_sent)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "3ee18ZKIQqgU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa91baa0-9436-42e5-82d3-0b9e120bea95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 130 ms, sys: 2.92 ms, total: 133 ms\n",
            "Wall time: 139 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "y_pred = [tagger.tag(xseq) for xseq in X_test]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Ns2UeFU5U96O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c55d966-2bfa-4789-b8fc-051112acb2a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        Amenity       0.42      0.30      0.35       533\n",
            "        Cuisine       0.49      0.46      0.48       532\n",
            "           Dish       0.32      0.21      0.25       288\n",
            "          Hours       0.59      0.42      0.49       212\n",
            "       Location       0.55      0.51      0.53       812\n",
            "          Price       0.49      0.35      0.40       171\n",
            "         Rating       0.52      0.51      0.52       201\n",
            "Restaurant_Name       0.39      0.24      0.30       402\n",
            "\n",
            "      micro avg       0.48      0.39      0.43      3151\n",
            "      macro avg       0.47      0.37      0.41      3151\n",
            "   weighted avg       0.48      0.39      0.42      3151\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from seqeval.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRMhFCCEBhds"
      },
      "source": [
        "# References\n",
        "\n",
        "1. Datasets for Entity Recognition: https://github.com/juand-r/entity-recognition-datasets\n",
        "2. [sklearn-crfsuite tutorial](https://sklearn-crfsuite.readthedocs.io/en/latest/tutorial.html#let-s-use-conll-2002-data-to-build-a-ner-system).\n",
        "3. [Quick Recipe: Build a POS tagger using a Conditional Random Field](https://nlpforhackers.io/crf-pos-tagger/)\n",
        "4. [NLP Guide: Identifying Part of Speech Tags using Conditional Random Fields](https://medium.com/analytics-vidhya/pos-tagging-using-conditional-random-fields-92077e5eaa31)\n",
        "5. [CRFsuite - Tutorial on Chunking Task](http://www.chokkan.org/software/crfsuite/tutorial.html)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}