{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Word Semantics and Embeddings\n",
        "\n",
        "March 2, 2024\n",
        "\n",
        "Your name: Nguyen Son\n",
        "\n",
        "Student ID: BI12-389\n",
        "\n",
        "In this programming assignment, you will write Python code to complete exercises about word vectors.\n",
        "\n",
        "You can use the library [gensim](https://radimrehurek.com/gensim/) or other libraries to complete exercises."
      ],
      "metadata": {
        "id": "R7Tz61-PCU78"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How to submit\n",
        "\n",
        "**Due date**: March 15, 2024\n",
        "\n",
        "- Make a copy of the notebook\n",
        "- Write your name and student ID into this notebook\n",
        "- Name your file as YourName_StudentID_Assignment1.ibynb. E.g., Nguyen_Van_A_ST099834_Assignment3.ipynb\n",
        "- Complete exercises\n",
        "- Attach notebook file (.ipynb) and submit your work to Google Class Room\n",
        "- Copying others' assignments is strictly prohibited."
      ],
      "metadata": {
        "id": "bMtaCIkuYwA4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 1 (20 points)\n",
        "\n",
        "Download [word vectors](https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?usp=sharing) that are pretrained on Google News dataset (approx. 100 billion words). The file contains word vectors of 3 million words/phrases, whose dimentionalities are 300. Print out the word vector of the term “United States”. Note that “United States” is represented as “United_States” in the file."
      ],
      "metadata": {
        "id": "msn-BAl6oZvn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2trsf766OSl",
        "outputId": "25a7ebca-859e-46a8-86de-6fa7836c8fd6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: Write your code here\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "filename = '/content/drive/My Drive/GoogleNews-vectors-negative300.bin.gz'\n",
        "model = KeyedVectors.load_word2vec_format(filename, binary=True)\n",
        "\n",
        "united_states_vector = model['United_States']\n",
        "print(united_states_vector)"
      ],
      "metadata": {
        "id": "cDAw1D6Xp1YC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2a06565-0fbb-4e27-d92b-76e3444dc38b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-3.61328125e-02 -4.83398438e-02  2.35351562e-01  1.74804688e-01\n",
            " -1.46484375e-01 -7.42187500e-02 -1.01562500e-01 -7.71484375e-02\n",
            "  1.09375000e-01 -5.71289062e-02 -1.48437500e-01 -6.00585938e-02\n",
            "  1.74804688e-01 -7.71484375e-02  2.58789062e-02 -7.66601562e-02\n",
            " -3.80859375e-02  1.35742188e-01  3.75976562e-02 -4.19921875e-02\n",
            " -3.56445312e-02  5.34667969e-02  3.68118286e-04 -1.66992188e-01\n",
            " -1.17187500e-01  1.41601562e-01 -1.69921875e-01 -6.49414062e-02\n",
            " -1.66992188e-01  1.00585938e-01  1.15722656e-01 -2.18750000e-01\n",
            " -9.86328125e-02 -2.56347656e-02  1.23046875e-01 -3.54003906e-02\n",
            " -1.58203125e-01 -1.60156250e-01  2.94189453e-02  8.15429688e-02\n",
            "  6.88476562e-02  1.87500000e-01  6.49414062e-02  1.15234375e-01\n",
            " -2.27050781e-02  3.32031250e-01 -3.27148438e-02  1.77734375e-01\n",
            " -2.08007812e-01  4.54101562e-02 -1.23901367e-02  1.19628906e-01\n",
            "  7.44628906e-03 -9.03320312e-03  1.14257812e-01  1.69921875e-01\n",
            " -2.38281250e-01 -2.79541016e-02 -1.21093750e-01  2.47802734e-02\n",
            "  7.71484375e-02 -2.81982422e-02 -4.71191406e-02  1.78222656e-02\n",
            " -1.23046875e-01 -5.32226562e-02  2.68554688e-02 -3.11279297e-02\n",
            " -5.59082031e-02 -5.00488281e-02 -3.73535156e-02  1.25976562e-01\n",
            "  5.61523438e-02  1.51367188e-01  4.29687500e-02 -2.08007812e-01\n",
            " -4.78515625e-02  2.78320312e-02  1.81640625e-01  2.20703125e-01\n",
            " -3.61328125e-02 -8.39843750e-02 -3.69548798e-05 -9.52148438e-02\n",
            " -1.25000000e-01 -1.95312500e-01 -1.50390625e-01 -4.15039062e-02\n",
            "  1.31835938e-01  1.17675781e-01  1.91650391e-02  5.51757812e-02\n",
            " -9.42382812e-02 -1.08886719e-01  7.32421875e-02 -1.15234375e-01\n",
            "  8.93554688e-02 -1.40625000e-01  1.45507812e-01  4.49218750e-02\n",
            " -1.10473633e-02 -1.62353516e-02  4.05883789e-03  3.75976562e-02\n",
            " -6.98242188e-02 -5.46875000e-02  2.17285156e-02 -9.47265625e-02\n",
            "  4.24804688e-02  1.81884766e-02 -1.73339844e-02  4.63867188e-02\n",
            " -1.42578125e-01  1.99218750e-01  1.10839844e-01  2.58789062e-02\n",
            " -7.08007812e-02 -5.54199219e-02  3.45703125e-01  1.61132812e-01\n",
            " -2.44140625e-01 -2.59765625e-01 -9.71679688e-02  8.00781250e-02\n",
            " -8.78906250e-02 -7.22656250e-02  1.42578125e-01 -8.54492188e-02\n",
            " -3.18359375e-01  8.30078125e-02  6.34765625e-02  1.64062500e-01\n",
            " -1.92382812e-01 -1.17675781e-01 -5.41992188e-02 -1.56250000e-01\n",
            " -1.21582031e-01 -4.95605469e-02  1.20117188e-01 -3.83300781e-02\n",
            "  5.51757812e-02 -8.97216797e-03  4.32128906e-02  6.93359375e-02\n",
            "  8.93554688e-02  2.53906250e-01  1.65039062e-01  1.64062500e-01\n",
            " -1.41601562e-01  4.58984375e-02  1.97265625e-01 -8.98437500e-02\n",
            "  3.90625000e-02 -1.51367188e-01 -8.60595703e-03 -1.17675781e-01\n",
            " -1.97265625e-01 -1.12792969e-01  1.29882812e-01  1.96289062e-01\n",
            "  1.56402588e-03  3.93066406e-02  2.17773438e-01 -1.43554688e-01\n",
            "  6.03027344e-02 -1.35742188e-01  1.16210938e-01 -1.59912109e-02\n",
            "  2.79296875e-01  1.46484375e-01 -1.19628906e-01  1.76757812e-01\n",
            "  1.28906250e-01 -1.49414062e-01  6.93359375e-02 -1.72851562e-01\n",
            "  9.22851562e-02  1.33056641e-02 -2.00195312e-01 -9.76562500e-02\n",
            " -1.65039062e-01 -2.46093750e-01 -2.35595703e-02 -2.11914062e-01\n",
            "  1.84570312e-01 -1.85546875e-02  2.16796875e-01  5.05371094e-02\n",
            "  2.02636719e-02  4.25781250e-01  1.28906250e-01 -2.77099609e-02\n",
            "  1.29882812e-01 -1.15722656e-01 -2.05078125e-02  1.49414062e-01\n",
            "  7.81250000e-03 -2.05078125e-01 -8.05664062e-02 -2.67578125e-01\n",
            " -2.29492188e-02 -8.20312500e-02  8.64257812e-02  7.61718750e-02\n",
            " -3.66210938e-02  5.22460938e-02 -1.22070312e-01 -1.44042969e-02\n",
            " -2.69531250e-01  8.44726562e-02 -2.52685547e-02 -2.96630859e-02\n",
            " -1.68945312e-01  1.93359375e-01 -1.08398438e-01  1.94091797e-02\n",
            " -1.80664062e-01  1.93359375e-01 -7.08007812e-02  5.85937500e-02\n",
            " -1.01562500e-01 -1.31835938e-01  7.51953125e-02 -7.66601562e-02\n",
            "  3.37219238e-03 -8.59375000e-02  1.25000000e-01  2.92968750e-02\n",
            "  1.70898438e-01 -9.37500000e-02 -1.09375000e-01 -2.50244141e-02\n",
            "  2.11914062e-01 -4.44335938e-02  6.12792969e-02  2.62451172e-02\n",
            " -1.77734375e-01  1.23046875e-01 -7.42187500e-02 -1.67968750e-01\n",
            " -1.08886719e-01 -9.04083252e-04 -7.37304688e-02  5.49316406e-02\n",
            "  6.03027344e-02  8.39843750e-02  9.17968750e-02 -1.32812500e-01\n",
            "  1.22070312e-01 -8.78906250e-03  1.19140625e-01 -1.94335938e-01\n",
            " -6.64062500e-02 -2.07031250e-01  7.37304688e-02  8.93554688e-02\n",
            "  1.81884766e-02 -1.20605469e-01 -2.61230469e-02  2.67333984e-02\n",
            "  7.76367188e-02 -8.30078125e-02  6.78710938e-02 -3.54003906e-02\n",
            "  3.10546875e-01 -2.42919922e-02 -1.41601562e-01 -2.08007812e-01\n",
            " -4.57763672e-03 -6.54296875e-02 -4.95605469e-02  2.22656250e-01\n",
            "  1.53320312e-01 -1.38671875e-01 -5.24902344e-02  4.24804688e-02\n",
            " -2.38281250e-01  1.56250000e-01  5.83648682e-04 -1.20605469e-01\n",
            " -9.22851562e-02 -4.44335938e-02  3.61328125e-02 -1.86767578e-02\n",
            " -8.25195312e-02 -8.25195312e-02 -4.05273438e-02  1.19018555e-02\n",
            "  1.69921875e-01 -2.80761719e-02  3.03649902e-03  9.32617188e-02\n",
            " -8.49609375e-02  1.57470703e-02  7.03125000e-02  1.62353516e-02\n",
            " -2.27050781e-02  3.51562500e-02  2.47070312e-01 -2.67333984e-02]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 2 (20 points)\n",
        "\n",
        "Compute the cosine similarity between “United States” and “U.S.”"
      ],
      "metadata": {
        "id": "lm31XvAfrlrN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: Write your code here\n",
        "united_states_vector = model['United_States']\n",
        "us_vector = model['U.S.']\n",
        "\n",
        "cosine_similarity = model.similarity('United_States', 'U.S.')\n",
        "print(cosine_similarity)"
      ],
      "metadata": {
        "id": "gQDoB9p0rtYE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e58ab737-58a2-4d73-e6d3-51002e2e6e52"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.73107743\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 3 (20 points)\n",
        "\n",
        "Find the top-10 words that have the highest cosine similarity with the word “United States” and print out the similarity score."
      ],
      "metadata": {
        "id": "LopFssN_rwcV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: Write your code here\n",
        "top_10_similar_words = model.most_similar('United_States', topn=10)\n",
        "for word, similarity in top_10_similar_words:\n",
        "    print(f\"{word}: {similarity}\")\n"
      ],
      "metadata": {
        "id": "7sYGLaSkr1yf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fea84ff9-e63f-4bf8-ddf4-1d1dcc303f66"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unites_States: 0.7877248525619507\n",
            "Untied_States: 0.7541370987892151\n",
            "United_Sates: 0.7400724291801453\n",
            "U.S.: 0.7310774326324463\n",
            "theUnited_States: 0.6404393911361694\n",
            "America: 0.6178410053253174\n",
            "UnitedStates: 0.6167312264442444\n",
            "Europe: 0.6132988929748535\n",
            "countries: 0.6044804453849792\n",
            "Canada: 0.601906955242157\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 4 (20 points)\n",
        "\n",
        "Subtract the vector of “Madrid” from the vector of “Spain” and then add the vector of “Athens”. Compute the top-10 most similar words with the output vector."
      ],
      "metadata": {
        "id": "tS8fsHOrr5AX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: Write your code here\n",
        "result_vector = model['Spain'] - model['Madrid'] + model['Athens']\n",
        "\n",
        "top_10_similar_words = model.most_similar([result_vector], topn=10)\n",
        "\n",
        "for word, similarity in top_10_similar_words:\n",
        "    print(f\"{word}: {similarity}\")\n"
      ],
      "metadata": {
        "id": "4d143lrfsBZv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7d0dba2-8982-4f27-f639-9fa811cb06ce"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Athens: 0.7528455853462219\n",
            "Greece: 0.6685472130775452\n",
            "Aristeidis_Grigoriadis: 0.5495778322219849\n",
            "Ioannis_Drymonakos: 0.5361457467079163\n",
            "Greeks: 0.5351786017417908\n",
            "Ioannis_Christou: 0.5330225825309753\n",
            "Hrysopiyi_Devetzi: 0.5088489055633545\n",
            "Iraklion: 0.5059264302253723\n",
            "Greek: 0.5040615797042847\n",
            "Athens_Greece: 0.5034108757972717\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 5 (20 points)\n",
        "\n",
        "Download [word analogy evaluation dataset](http://download.tensorflow.org/data/questions-words.txt). Compute the vector as follows: vec(word in second column) - vec(word in first column) + vec(word in third column). From the output vector, find the most similar word. Append the most similar word and its similarity to each row of the downloaded file."
      ],
      "metadata": {
        "id": "gkZP38QWsEJX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: Write your code here\n",
        "data_path = '/content/drive/My Drive/capital-common-countries.txt'\n",
        "\n",
        "with open(data_path, 'r') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "modified_lines = []\n",
        "for line in lines[1:]:\n",
        "    words = line.strip().split()\n",
        "    try:\n",
        "        result_vector = model[words[1]] - model[words[0]] + model[words[2]]\n",
        "        most_similar = model.similar_by_vector(result_vector, topn=1)[0]\n",
        "        modified_line = f\"{line.strip()} {most_similar[0]} {most_similar[1]}\"\n",
        "        modified_lines.append(modified_line)\n",
        "    except KeyError as e:\n",
        "        print(f\"Error processing line: {line.strip()} - {e}\")\n",
        "\n",
        "modified_data_path = '/content/drive/My Drive/capital-common-countries-modify.txt'\n",
        "with open(modified_data_path, 'w') as modified_file:\n",
        "    for line in modified_lines:\n",
        "        modified_file.write(f\"{line}\\n\")\n"
      ],
      "metadata": {
        "id": "0aqYLkGhsYB1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a578d0bc-3d0e-4d5b-d3a0-87f2717035a5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing line: : capital-world - \"Key 'capital-world' not present\"\n",
            "Error processing line: : currency - \"Key ':' not present\"\n",
            "Error processing line: : city-in-state - \"Key 'city-in-state' not present\"\n",
            "Error processing line: : family - \"Key ':' not present\"\n",
            "Error processing line: : gram1-adjective-to-adverb - \"Key 'gram1-adjective-to-adverb' not present\"\n",
            "Error processing line: : gram2-opposite - \"Key 'gram2-opposite' not present\"\n",
            "Error processing line: : gram3-comparative - \"Key 'gram3-comparative' not present\"\n",
            "Error processing line: : gram4-superlative - \"Key 'gram4-superlative' not present\"\n",
            "Error processing line: : gram5-present-participle - \"Key 'gram5-present-participle' not present\"\n",
            "Error processing line: : gram6-nationality-adjective - \"Key 'gram6-nationality-adjective' not present\"\n",
            "Error processing line: : gram7-past-tense - \"Key 'gram7-past-tense' not present\"\n",
            "Error processing line: : gram8-plural - \"Key 'gram8-plural' not present\"\n",
            "Error processing line: : gram9-plural-verbs - \"Key 'gram9-plural-verbs' not present\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 6 (Bonus points)\n",
        "\n",
        "From the output of the exercise 5, compute the accuracy score. It means that you will calculate the percentage of cases in which the most similar words returned by your code are the same as the words in 4th column.\n",
        "\n"
      ],
      "metadata": {
        "id": "a1hShhvdsaxo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: Write your code here\n",
        "correct_predictions = 0\n",
        "total_predictions = 0\n",
        "\n",
        "for line in modified_lines:\n",
        "    parts = line.strip().split()\n",
        "    if len(parts) >= 6:\n",
        "        correct_word = parts[3]\n",
        "        predicted_word = parts[4]\n",
        "        total_predictions += 1\n",
        "        if predicted_word == correct_word:\n",
        "            correct_predictions += 1\n",
        "\n",
        "accuracy = (correct_predictions / total_predictions) * 100 if total_predictions > 0 else 0\n",
        "\n",
        "print(f\"Accuracy Score: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "G7UYdv-Nsdh-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3a4c024-a010-4bf7-be62-f5ea245038de"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score: 20.19%\n"
          ]
        }
      ]
    }
  ]
}